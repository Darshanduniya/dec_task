from datetime import datetime
from airflow import DAG
from airflow.providers.ssh.operators.ssh import SSHOperator

# Define default arguments
default_args = {
    'owner': 'airflow',
    'depends_on_past': False,
    'email_on_failure': False,
    'email_on_retry': False,
    'retries': 1
}

# Define the DAG
with DAG('ssh_dag',
         default_args=default_args,
         description='A DAG to run scripts using SSHOperator',
         schedule_interval=None,
         start_date=datetime(2024, 1, 5),
         catchup=False) as dag:

    # Task 1: Run script 1
    task1 = SSHOperator(
        task_id='run_script1',
        ssh_conn_id='your_ssh_connection',  # Ensure you have an SSH connection configured in Airflow
        command="""
        python /path_to_script1/script1.py arg1 arg2
        """,
    )

    # Task 2: Run script 2
    task2 = SSHOperator(
        task_id='run_script2',
        ssh_conn_id='your_ssh_connection',  # Ensure you have an SSH connection configured in Airflow
        command="""
        python /path_to_script2/script2.py
        """,
        params={
            'model_name': "{{ task_instance.xcom_pull(task_ids='run_script1', key='return_value')[0] }}",
            'ab_server': "{{ task_instance.xcom_pull(task_ids='run_script1', key='return_value')[1] }}",
            'ab_path': "{{ task_instance.xcom_pull(task_ids='run_script1', key='return_value')[2] }}"
        }
    )

    # Define the task dependencies
    task1 >> task2
